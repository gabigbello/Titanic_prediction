{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics as st\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "#machine learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"train.csv\",sep=',')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Cleaning \"train.csv\"\n",
    "\n",
    "#Treating empty values\n",
    "\n",
    "dataset.isnull().sum()\n",
    "\n",
    "#Age column\n",
    "empty = dataset['Age'].isna().sum()\n",
    "median_age = dataset['Age'].median()\n",
    "dataset['Age'] = dataset['Age'].fillna(median_age)\n",
    "dataset.isnull().sum()\n",
    "\n",
    "#Cabin column\n",
    "cabin_grouped = dataset.groupby(dataset['Cabin']).size().sort_values(ascending=False)\n",
    "most_common_values = [\"C23 C25 C27\",\"G6\",\"B96 B98\"] #group of most shown values on the dataset for Cabin\n",
    "dataset['Cabin'] = dataset['Cabin'].fillna(pd.Series(np.random.choice(most_common_values,size=len(dataset.index))))\n",
    "dataset.isnull().sum()\n",
    "\n",
    "#Embarked\n",
    "embarked_grouped = dataset.groupby(dataset['Embarked']).size() #S is the higher \n",
    "dataset['Embarked'] = dataset['Embarked'].fillna('S')\n",
    "dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2}).astype(int)\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking and treating the Titles\n",
    "\n",
    "dataset['Title'] = dataset['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "pd.crosstab(dataset['Title'],dataset['Sex'])\n",
    "\n",
    "dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess', 'Capt', 'Col','Don','Dr','Major','Rev','Sir','Jonkheer','Dona'], 'Rare')\n",
    "\n",
    "dataset['Title'] = dataset['Title'].replace('Mlle','Miss')\n",
    "dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
    "\n",
    "pd.crosstab(dataset['Title'],dataset['Sex'])\n",
    "dataset[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()\n",
    "\n",
    "#Setting titles to ints\n",
    "title_numbers = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
    "dataset['Title'] = dataset['Title'].map(title_numbers)\n",
    "dataset['Title'] = dataset['Title'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grouping ages in ranges\n",
    "\n",
    "dataset['Age'] = dataset['Age'].astype(int)\n",
    "\n",
    "dataset.loc[dataset['Age'] <= 18, 'Age'] = 0\n",
    "dataset.loc[(dataset['Age'] >= 18) & (dataset['Age'] <= 30), 'Age'] = 1\n",
    "dataset.loc[(dataset['Age'] >= 31) & (dataset['Age'] <= 40), 'Age'] = 2\n",
    "dataset.loc[(dataset['Age'] >= 41) & (dataset['Age'] <= 50), 'Age'] = 3\n",
    "dataset.loc[(dataset['Age'] >= 51) & (dataset['Age'] <= 60), 'Age'] = 4\n",
    "dataset.loc[dataset['Age'] >= 61, 'Age'] = 5\n",
    "\n",
    "age_grouped = dataset.groupby(dataset['Age']).size()\n",
    "age_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treating 'Sibsp' and 'Parch\n",
    "\n",
    "dataset['Family'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "\n",
    "dataset['IsAlone'] = 0\n",
    "dataset.loc[dataset['Family'] == 1, 'IsAlone'] = 1\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treating Fare\n",
    "\n",
    "fare_size = dataset.groupby(dataset['Fare']).size()\n",
    "fare_size\n",
    "\n",
    "dataset.loc[ dataset['Fare'] <= 8, 'Fare'] = 0\n",
    "dataset.loc[(dataset['Fare'] > 8) & (dataset['Fare'] <= 15), 'Fare'] = 1\n",
    "dataset.loc[(dataset['Fare'] > 15) & (dataset['Fare'] <= 31), 'Fare']   = 2\n",
    "dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\n",
    "\n",
    "fare_size = dataset.groupby(dataset['Fare']).size()\n",
    "fare_size\n",
    "\n",
    "dataset['Fare'] = dataset['Fare'].astype(int)\n",
    "\n",
    "fare_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treating Cabin letter\n",
    "\n",
    "#Transforming Cabin in only letters\n",
    "\n",
    "dataset['Cabin_letter'] = dataset['Cabin'].str[0]\n",
    "grouped_cabin = dataset.groupby('Cabin_letter').size()\n",
    "grouped_cabin\n",
    "\n",
    "cabin_mapping = {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'T': 7}\n",
    "dataset['Cabin_letter'] = dataset['Cabin_letter'].map(cabin_mapping).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treating sex\n",
    "\n",
    "dataset['Sex'] = dataset['Sex'].map({'female': 1, 'male':0}).astype(int)\n",
    "\n",
    "sex_size = dataset.groupby(dataset['Sex']).size()\n",
    "sex_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for duplicated data in id\n",
    "duplicated = dataset.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for wrong values on columns we have values specified:\n",
    "\n",
    "checking_survived = dataset.groupby(dataset['Survived']).size()\n",
    "checking_survived\n",
    "\n",
    "checking_pclass = dataset.groupby(dataset['Pclass']).size()\n",
    "checking_pclass\n",
    "\n",
    "checking_sex = dataset.groupby(dataset['Sex']).size()\n",
    "checking_sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for correlations - pivoting features against each other\n",
    "\n",
    "dataset[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n",
    "dataset[['Sex', 'Survived']].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n",
    "dataset[['Age', 'Survived']].groupby(['Age'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Creating some graphs to understand our dataset\n",
    "dataset.head()\n",
    "\n",
    "'''Not interesting for graphs:\n",
    "Name, Ticket, SibSp, Parch, PassengerId\n",
    "'''\n",
    "\n",
    "#Graph1: Sex x Survived\n",
    "#Graph2: Ages x Survived\n",
    "#Graph3: Fare x Survived\n",
    "#Graph4: PClass x Survived\n",
    "\n",
    "survived = (dataset[dataset['Survived'] == 1])\n",
    "survived_by_sex = (survived).groupby('Sex').size()\n",
    "\n",
    "bins = [0, 18, 30, 40, 50, 60, 80, float('inf')]\n",
    "labels = ['0-18','19-30','31-40','41-50','51-60','61-80','81+']\n",
    "\n",
    "survived['age_1']=pd.cut(survived['Age'],bins=bins, labels=labels, right=False)\n",
    "survived_by_age = survived.groupby('age_1').size()\n",
    "\n",
    "bins_fare = [0, 100, 200, 300, 400, 500, 600]\n",
    "labels_fare = ['0-100','101-200','201-300','301-400','401-500','501-600']\n",
    "\n",
    "survived['fare_bins'] = pd.cut(survived['Fare'],bins=bins_fare, labels=labels_fare, right=False)\n",
    "survived_by_fare = survived.groupby('fare_bins').size()\n",
    "\n",
    "pclass_survived = (survived).groupby('Pclass').size()\n",
    "\n",
    "plt.figure(figsize=(15,9))\n",
    "plt.title('Informations of survivors')\n",
    "plt.subplot(2,2,1)\n",
    "survived_by_sex.plot(kind='bar',color='black')\n",
    "plt.subplot(2,2,2)\n",
    "survived_by_age.plot(kind='bar',color='black')\n",
    "plt.subplot(2,2,3)\n",
    "survived_by_fare.plot(kind='bar',color='black')\n",
    "plt.subplot(2,2,4)\n",
    "pclass_survived.plot(kind='bar',color='black')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Creating our x and y for train.csv\n",
    "\n",
    "drop_from_main = [\"Name\",\"Ticket\",\"PassengerId\",\"Cabin\",\"Survived\",\"SibSp\",\"Parch\",\"Family\",\"SibSp\",\"Parch\"]\n",
    "dataset_clean = dataset.drop(drop_from_main,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Importing and testing the \"test.csv\" dataset to predict \"Survived\"\n",
    "\n",
    "test_dataset = pd.read_csv(\"test.csv\", sep=',')\n",
    "test_dataset.head()\n",
    "test_dataset.describe()\n",
    "test_dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treating data for our test dataset:\n",
    "\n",
    "#Age\n",
    "\n",
    "td_median_age = test_dataset['Age'].median()\n",
    "td_median_age\n",
    "test_dataset['Age'] = test_dataset['Age'].fillna(td_median_age)\n",
    "\n",
    "#Cabin\n",
    "cabin_grouped_test = test_dataset.groupby(test_dataset['Cabin']).size().sort_values(ascending=False)\n",
    "test_dataset['Cabin'] = test_dataset['Cabin'].fillna(\"B57 B59 B63 B66\")\n",
    "test_dataset['Cabin_letter'] = test_dataset['Cabin'].str[0]\n",
    "grouped_cabin_test = dataset.groupby('Cabin_letter').size()\n",
    "\n",
    "#Fare\n",
    "td_fare_median = test_dataset['Fare'].median()\n",
    "td_fare_median\n",
    "test_dataset['Fare'] = test_dataset['Fare'].fillna(td_fare_median)\n",
    "\n",
    "#Checking for wrong values\n",
    "\n",
    "checking_pclass = test_dataset.groupby(test_dataset['Pclass']).size()\n",
    "checking_pclass\n",
    "\n",
    "checking_sex = test_dataset.groupby(test_dataset['Sex']).size()\n",
    "checking_sex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treating all columns of our test.csv\n",
    "\n",
    "#Embarked\n",
    "embarked_grouped_test = test_dataset.groupby(test_dataset['Embarked']).size() #S is the higher \n",
    "test_dataset['Embarked'] = test_dataset['Embarked'].fillna('S')\n",
    "test_dataset['Embarked'] = test_dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2}).astype(int)\n",
    "\n",
    "#Checking and treating the Titles\n",
    "\n",
    "test_dataset['Title'] = test_dataset['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "pd.crosstab(test_dataset['Title'],test_dataset['Sex'])\n",
    "\n",
    "test_dataset['Title'] = test_dataset['Title'].replace(['Lady', 'Countess', 'Capt', 'Col','Don','Dr','Major','Rev','Sir','Jonkheer','Dona'], 'Rare')\n",
    "\n",
    "test_dataset['Title'] = test_dataset['Title'].replace('Mlle','Miss')\n",
    "test_dataset['Title'] = test_dataset['Title'].replace('Ms', 'Miss')\n",
    "test_dataset['Title'] = test_dataset['Title'].replace('Mme', 'Mrs')\n",
    "\n",
    "pd.crosstab(test_dataset['Title'],test_dataset['Sex'])\n",
    "\n",
    "#Setting titles to ints\n",
    "title_numbers_test = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
    "test_dataset['Title'] = test_dataset['Title'].map(title_numbers_test)\n",
    "test_dataset['Title'] = test_dataset['Title'].fillna(0)\n",
    "\n",
    "#Grouping ages in ranges\n",
    "\n",
    "test_dataset['Age'] = test_dataset['Age'].astype(int)\n",
    "\n",
    "test_dataset.loc[test_dataset['Age'] <= 18, 'Age'] = 0\n",
    "test_dataset.loc[(test_dataset['Age'] >= 18) & (test_dataset['Age'] <= 30), 'Age'] = 1\n",
    "test_dataset.loc[(test_dataset['Age'] >= 31) & (test_dataset['Age'] <= 40), 'Age'] = 2\n",
    "test_dataset.loc[(test_dataset['Age'] >= 41) & (test_dataset['Age'] <= 50), 'Age'] = 3\n",
    "test_dataset.loc[(test_dataset['Age'] >= 51) & (test_dataset['Age'] <= 60), 'Age'] = 4\n",
    "test_dataset.loc[test_dataset['Age'] >= 61, 'Age'] = 5\n",
    "\n",
    "age_grouped_test = test_dataset.groupby(test_dataset['Age']).size()\n",
    "age_grouped_test\n",
    "\n",
    "#Treating 'Sibsp' and 'Parch\n",
    "\n",
    "test_dataset['Family'] = test_dataset['SibSp'] + test_dataset['Parch'] + 1\n",
    "\n",
    "test_dataset['IsAlone'] = 0\n",
    "test_dataset.loc[test_dataset['Family'] == 1, 'IsAlone'] = 1\n",
    "\n",
    "#Treating Fare\n",
    "\n",
    "fare_size = test_dataset.groupby(test_dataset['Fare']).size()\n",
    "fare_size\n",
    "\n",
    "test_dataset.loc[ test_dataset['Fare'] <= 8, 'Fare'] = 0\n",
    "test_dataset.loc[(test_dataset['Fare'] > 8) & (test_dataset['Fare'] <= 15), 'Fare'] = 1\n",
    "test_dataset.loc[(test_dataset['Fare'] > 15) & (test_dataset['Fare'] <= 31), 'Fare']   = 2\n",
    "test_dataset.loc[ test_dataset['Fare'] > 31, 'Fare'] = 3\n",
    "\n",
    "fare_size = test_dataset.groupby(test_dataset['Fare']).size()\n",
    "fare_size\n",
    "\n",
    "test_dataset['Fare'] = test_dataset['Fare'].astype(int)\n",
    "\n",
    "#Treating Cabin letter\n",
    "\n",
    "#Transforming Cabin in only letters\n",
    "\n",
    "test_dataset['Cabin_letter'] = test_dataset['Cabin'].str[0]\n",
    "grouped_cabin_test = test_dataset.groupby('Cabin_letter').size()\n",
    "grouped_cabin_test\n",
    "\n",
    "cabin_mapping = {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'T': 7}\n",
    "test_dataset['Cabin_letter'] = test_dataset['Cabin_letter'].map(cabin_mapping).astype(int)\n",
    "\n",
    "#Treating sex\n",
    "\n",
    "test_dataset['Sex'] = test_dataset['Sex'].map({'female': 1, 'male':0}).astype(int)\n",
    "\n",
    "sex_size = test_dataset.groupby(test_dataset['Sex']).size()\n",
    "sex_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping some columns that we don't need\n",
    "\n",
    "keys_to_drop = ['Name','Ticket','Cabin','SibSp','Parch','Family']\n",
    "\n",
    "test_dataset_clean = test_dataset.drop(keys_to_drop, axis=1)\n",
    "test_dataset_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reordering test table\n",
    "\n",
    "new_order = ['Pclass','Sex','Age','Fare','Embarked','Title','IsAlone','Cabin_letter']\n",
    "test_dataset_clean = test_dataset_clean[new_order]\n",
    "\n",
    "test_dataset_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAINING AND PREDICTING\n",
    "\n",
    "#Train.csv\n",
    "#x = dataset_clean\n",
    "#y = dataset['Survived']\n",
    "\n",
    "#Test.csv\n",
    "#x = test_dataset_clean\n",
    "\n",
    "x_tr = dataset_clean\n",
    "y_tr = dataset['Survived']\n",
    "x_te = test_dataset_clean\n",
    "x_tr.shape, y_tr.shape, x_te.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Logistic Regression\n",
    "KNN or k-Nearest Neighbors\n",
    "Support Vector Machines\n",
    "Naive Bayes classifier\n",
    "Decision Tree\n",
    "Random Forrest\n",
    "Perceptron\n",
    "Artificial neural network\n",
    "RVM or Relevance Vector Machine\n",
    "'''\n",
    "\n",
    "#a. Logistic Regression\n",
    "l_reg = LogisticRegression()\n",
    "l_reg.fit(x_tr,y_tr)\n",
    "y_pred = l_reg.predict(x_te)\n",
    "score_log = round(l_reg.score(x_tr,y_tr)*100,2)\n",
    "score_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#b. Support Vector Machines\n",
    "svc = SVC()\n",
    "svc.fit(x_tr,y_tr)\n",
    "y_pred = svc.predict(x_te)\n",
    "score_svc = round(svc.score(x_tr,y_tr)*100,2)\n",
    "score_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c. k-Nearest Neighbors\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "knn.fit(x_tr,y_tr)\n",
    "y_pred = knn.predict(x_te)\n",
    "score_knn = round(knn.score(x_tr,y_tr)*100,2)\n",
    "score_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d. Gaussian Naive Bayes\n",
    "\n",
    "gaussian = GaussianNB()\n",
    "gaussian.fit(x_tr,y_tr)\n",
    "y_pred = gaussian.predict(x_te)\n",
    "score_gaussian = round(gaussian.score(x_tr,y_tr)*100,2)\n",
    "score_gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#e. Perceptron\n",
    "\n",
    "perceptron = Perceptron()\n",
    "perceptron.fit(x_tr,y_tr)\n",
    "y_pred = perceptron.predict(x_te)\n",
    "score_perceptron = round(perceptron.score(x_tr,y_tr)*100,2)\n",
    "score_perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f. Linear SVC\n",
    "\n",
    "linear_svc = LinearSVC()\n",
    "linear_svc.fit(x_tr,y_tr)\n",
    "y_pred = linear_svc.predict(x_te)\n",
    "score_linear_svc = round(linear_svc.score(x_tr,y_tr)*100,2)\n",
    "score_linear_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#g. Stochastic Gradient Descent\n",
    "\n",
    "sgd = SGDClassifier()\n",
    "sgd.fit(x_tr,y_tr)\n",
    "y_pred = sgd.predict(x_te)\n",
    "score_sgd = round(sgd.score(x_tr,y_tr)*100,2)\n",
    "score_sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#h. Decision Tree\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "decision_tree.fit(x_tr, y_tr)\n",
    "y_pred = decision_tree.predict(x_te)\n",
    "score_decision_tree = round(decision_tree.score(x_tr, y_tr) * 100, 2)\n",
    "score_decision_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i. Random Forest\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators=100)\n",
    "random_forest.fit(x_tr, y_tr)\n",
    "y_pred = random_forest.predict(x_te)\n",
    "score_random_forest = round(random_forest.score(x_tr, y_tr) * 100, 2)\n",
    "score_random_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Models evaluation\n",
    "\n",
    "models_evaluation = pd.DataFrame({\n",
    "    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', 'Random Forest', 'Naive Bayes', 'Perceptron', \n",
    "    'Stochastic Gradient Decent', 'Linear SVC', 'Decision Tree'],\n",
    "    'Score': [score_random_forest, score_decision_tree, score_sgd, score_linear_svc, score_perceptron, score_gaussian, score_knn, \n",
    "                score_svc,score_log]})\n",
    "\n",
    "models_evaluation.sort_values(by='Score',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating our submission dataset\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"PassengerId\": test_dataset['PassengerId'],\n",
    "    \"Survived\": y_pred\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('Submission file.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
