{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics as st\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"train.csv\",sep=',')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Cleaning \"train.csv\"\n",
    "\n",
    "#Treating empty values\n",
    "\n",
    "dataset.isnull().sum()\n",
    "\n",
    "#Age column\n",
    "empty = dataset['Age'].isna().sum()\n",
    "median_age = dataset['Age'].median()\n",
    "dataset['Age'] = dataset['Age'].fillna(median_age)\n",
    "dataset.isnull().sum()\n",
    "\n",
    "#Cabin column\n",
    "cabin_grouped = dataset.groupby(dataset['Cabin']).size().sort_values(ascending=False)\n",
    "most_common_values = [\"C23 C25 C27\",\"G6\",\"B96 B98\"] #group of most shown values on the dataset for Cabin\n",
    "dataset['Cabin'] = dataset['Cabin'].fillna(pd.Series(np.random.choice(most_common_values,size=len(dataset.index))))\n",
    "dataset.isnull().sum()\n",
    "\n",
    "#Embarked\n",
    "embarked_grouped = dataset.groupby(dataset['Embarked']).size() #S is the higher \n",
    "dataset['Embarked'] = dataset['Embarked'].fillna(\"S\")\n",
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for duplicated data in id\n",
    "duplicated = dataset.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for wrong values on columns we have values specified:\n",
    "\n",
    "checking_survived = dataset.groupby(dataset['Survived']).size()\n",
    "checking_survived\n",
    "\n",
    "checking_pclass = dataset.groupby(dataset['Pclass']).size()\n",
    "checking_pclass\n",
    "\n",
    "checking_sex = dataset.groupby(dataset['Sex']).size()\n",
    "checking_sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Creating some graphs to understand our dataset\n",
    "dataset.head()\n",
    "\n",
    "'''Not interesting for graphs:\n",
    "Name, Ticket, SibSp, Parch, PassengerId\n",
    "'''\n",
    "\n",
    "#Graph1: Sex x Survived\n",
    "#Graph2: Ages x Survived\n",
    "#Graph3: Fare x Survived\n",
    "#Graph4: PClass x Survived\n",
    "\n",
    "survived = (dataset[dataset['Survived'] == 1])\n",
    "survived_by_sex = (survived).groupby('Sex').size()\n",
    "\n",
    "bins = [0, 18, 30, 40, 50, 60, 80, float('inf')]\n",
    "labels = ['0-18','19-30','31-40','41-50','51-60','61-80','81+']\n",
    "\n",
    "survived['age_1']=pd.cut(survived['Age'],bins=bins, labels=labels, right=False)\n",
    "survived_by_age = survived.groupby('age_1').size()\n",
    "\n",
    "bins_fare = [0, 100, 200, 300, 400, 500, 600]\n",
    "labels_fare = ['0-100','101-200','201-300','301-400','401-500','501-600']\n",
    "\n",
    "survived['fare_bins'] = pd.cut(survived['Fare'],bins=bins_fare, labels=labels_fare, right=False)\n",
    "survived_by_fare = survived.groupby('fare_bins').size()\n",
    "\n",
    "pclass_survived = (survived).groupby('Pclass').size()\n",
    "\n",
    "plt.figure(figsize=(15,9))\n",
    "plt.title('Informations of survivors')\n",
    "plt.subplot(2,2,1)\n",
    "survived_by_sex.plot(kind='bar',color='black')\n",
    "plt.subplot(2,2,2)\n",
    "survived_by_age.plot(kind='bar',color='black')\n",
    "plt.subplot(2,2,3)\n",
    "survived_by_fare.plot(kind='bar',color='black')\n",
    "plt.subplot(2,2,4)\n",
    "pclass_survived.plot(kind='bar',color='black')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforming Cabin in only letters\n",
    "\n",
    "dataset['Cabin_letter'] = dataset['Cabin'].str[0]\n",
    "grouped_cabin = dataset.groupby('Cabin_letter').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Train our predict\n",
    "\n",
    "drop_from_main = [\"Name\",\"Ticket\",\"PassengerId\",\"Cabin\",\"Survived\"]\n",
    "dataset_clean = dataset.drop(drop_from_main,axis=1)\n",
    "\n",
    "#Preparing category columns\n",
    "data_encoded = pd.get_dummies(dataset_clean, columns=['Sex','Cabin_letter','Embarked'])\n",
    "\n",
    "x = data_encoded\n",
    "y = dataset['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create train and test splits with 20% for test\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "x_train = scaler.transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating our MLP \n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(9), activation='logistic',max_iter=10000,alpha=1e-6, solver='sgd', verbose=10,tol = 1e-9,\n",
    "                    random_state=1,learning_rate='adaptive', momentum=0.3,learning_rate_init=0.8 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training\n",
    "mlp.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting with test\n",
    "predictions = mlp.predict(x_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix\n",
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classification report\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Importing and testing the \"test.csv\" dataset to predict \"Survived\"\n",
    "\n",
    "test_dataset = pd.read_csv(\"test.csv\", sep=',')\n",
    "test_dataset.head()\n",
    "test_dataset.describe()\n",
    "test_dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treating data for our test dataset:\n",
    "\n",
    "#Age\n",
    "\n",
    "td_median_age = test_dataset['Age'].median()\n",
    "td_median_age\n",
    "test_dataset['Age'] = test_dataset['Age'].fillna(td_median_age)\n",
    "\n",
    "#Cabin\n",
    "cabin_grouped_test = test_dataset.groupby(test_dataset['Cabin']).size().sort_values(ascending=False)\n",
    "test_dataset['Cabin'] = test_dataset['Cabin'].fillna(\"B57 B59 B63 B66\")\n",
    "test_dataset['Cabin_letter'] = test_dataset['Cabin'].str[0]\n",
    "grouped_cabin_test = dataset.groupby('Cabin_letter').size()\n",
    "\n",
    "#Fare\n",
    "td_fare_median = test_dataset['Fare'].median()\n",
    "td_fare_median\n",
    "test_dataset['Fare'] = test_dataset['Fare'].fillna(td_fare_median)\n",
    "\n",
    "#Checking for wrong values\n",
    "\n",
    "checking_pclass = test_dataset.groupby(test_dataset['Pclass']).size()\n",
    "checking_pclass\n",
    "\n",
    "checking_sex = test_dataset.groupby(test_dataset['Sex']).size()\n",
    "checking_sex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping some columns that we don't need\n",
    "\n",
    "keys_to_drop = ['Name','Ticket','Cabin', 'PassengerId']\n",
    "\n",
    "test_dataset_clean = test_dataset.drop(keys_to_drop, axis=1)\n",
    "test_dataset_clean.head()\n",
    "\n",
    "test_data_encoded = pd.get_dummies(test_dataset_clean, columns=['Sex','Cabin_letter','Embarked'])\n",
    "\n",
    "test_data_encoded['Cabin_letter_T'] = False\n",
    "\n",
    "x_new = test_data_encoded\n",
    "x_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabi Bello\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Predict 'Survived'\n",
    "test_dataset_clean['Survived'] = mlp.predict(x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived\n",
      "0    216\n",
      "1    202\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "survived_counts = test_dataset_clean['Survived'].value_counts()\n",
    "print(survived_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_clean['PassengerId'] = test_dataset['PassengerId']\n",
    "test_dataset_clean\n",
    "\n",
    "columns_to_drop = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'Cabin_letter']\n",
    "\n",
    "final = test_dataset_clean.drop(columns_to_drop,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving our final table with the predictions\n",
    "final.to_csv('final_prediction.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
